# Full GPU-enabled LLM pipeline requirements
# Only includes packages NOT pre-installed in nvcr.io/nvidia/pytorch:25.02-py3

# Pre-installed: torch 2.7.0a0, torchvision, pytorch-triton, tensorrt 10.8.0, onnx, numpy, transformer_engine 2.2, safetensors

# Core ML dependencies - only missing packages
transformers>=4.55.1
tokenizers>=0.13.0

# ONNX dependencies - onnx already pre-installed, add runtime
onnxruntime-gpu>=1.15.0

# MegaBlocks dependencies (installed before MegaBlocks with --no-deps)
stanford-stk

# Server dependencies
fastapi>=0.100.0
uvicorn[standard]>=0.22.0
pydantic>=2.0.0

# Client dependencies
openai>=1.0.0
aiohttp>=3.8.0

# Utility dependencies - numpy pre-installed
PyYAML>=6.0
packaging>=21.0

# Dashboard dependencies
Jinja2>=3.1.0

# CUDA utilities - some may be pre-installed in TensorRT container
nvidia-ml-py>=12.535.0

# Optional: for better logging and progress bars
tqdm>=4.65.0
rich>=13.0.0

# Hugging Face hub
huggingface_hub>=0.16.0

# Accelerate for multi-GPU support
accelerate>=0.20.0

# Required for GPT-OSS-20B optimizations
# Note: triton pre-installed as pytorch-triton
kernels>=0.1.0

# Note: megablocks installed separately with --no-deps to avoid torch conflicts